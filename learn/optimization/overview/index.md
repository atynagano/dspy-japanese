# DSPyにおける最適化手法

システムを構築し、その評価方法を確立した後、DSPyの最適化機能を活用することで、プログラムのプロンプトパラメータや重み係数の調整が可能になります。探索目的で使用していた開発セットに加え、トレーニングセットとホールドアウトテストセットの構築にデータ収集の取り組みを拡大することが有効です。トレーニングセット（およびそのサブセットである検証セット）については、30例程度でも一定の効果が得られますが、少なくとも300例程度のデータ収集を目指すことをお勧めします。一部の最適化アルゴリズムでは`trainset`のみを必要としますが、他のアルゴリズムでは`trainset`と`valset`の両方を指定する必要があります。ほとんどのプロンプト最適化アルゴリズムにおいてデータ分割を行う場合、深層ニューラルネットワークとは異なる特異な分割方法を推奨します：トレーニング用に20%、検証用に80%を割り当てます。この逆配分は、プロンプトベースの最適化アルゴリズムが小規模なトレーニングセットに対して過学習しやすい特性を考慮したものです。一方、[dspy.GEPA](https://dspy.ai/tutorials/gepa_ai_program/)最適化アルゴリズムはより標準的な機械学習の慣習に従っています：トレーニングセットのサイズを最大化しつつ、検証セットは下流タスク（テストセット）の分布を適切に反映できる最小限のサイズに留めるという手法を採用しています。

最初の数回の最適化試行後、以下のいずれかの状況に至るでしょう：全ての結果に大変満足するか、大幅な進展は見られるものの、最終的なプログラムや評価指標の何らかの点に不満が残るかです。このような場合、ステップ1（DSPyにおけるプログラミング）に戻り、主要な検討事項を再評価してください。タスク定義は適切に行われていますか？問題領域に対してさらにデータを収集する（あるいはオンラインで適切なデータを探す）必要はありませんか？評価指標の更新を検討すべきでしょうか？より高度な最適化アルゴリズムを採用する必要はありますか？DSPyアサーションのような先進的な機能を考慮すべきでしょうか？あるいは、最も重要な点として、DSPyプログラム自体にさらなる複雑性や処理ステップを追加する必要があるでしょうか？複数の最適化アルゴリズムを順次適用する方法も検討すべきでしょうか？

反復的な開発プロセスが重要です。DSPyは、データ、プログラム構造、評価指標、最適化手順を段階的に改良していくための必要な要素をすべて提供しています。複雑な大規模言語モデル（LM）プログラムの最適化は、執筆時点ではDSPy独自の全く新しいパラダイムです（注：現在では多数のDSPy拡張フレームワークが存在し、この部分は必ずしも正確ではありません：-)）。そのため、最適な実践方法に関する規範はまだ形成途上にあります。支援が必要な場合、私たちは最近、コミュニティ向けの[Discordサーバー](https://discord.gg/XCGy2WDCQB)を開設しました。
