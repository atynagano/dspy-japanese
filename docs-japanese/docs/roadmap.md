---
draft: true
---

!!! warning "本文書は2024年8月時点の内容です。その後、DSPy 2.5および2.6がリリースされ、DSPyは大幅に進化しており、3.0のリリースも間近に迫っています！以下の内容は大幅に古くなっている可能性がありますのでご注意ください。"



# ロードマップ概要：DSPy 2.5以降の展望

DSPyがDemonstrate–Search–Predict（DSP）フレームワークから発展して以来、1年が経過しました。2022年2月にスタンフォードNLP研究所で研究が開始されて以来、200名を超える素晴らしい貢献者の方々の尽力により、DSPyは数万人ものユーザーにモジュール型言語モデルプログラムの構築方法と、プロンプトやパラメータの自動最適化手法を紹介することに成功しました。この間、DSPyの月間ダウンロード数は16万回に達し、GitHubでは1.6万スターを獲得するまでに成長し、多くの分野でプロンプト最適化の代名詞的存在となるとともに、少なくとも6つの新しい優れたライブラリの開発にインスピレーションを与えてきました。

本文書は、DSPy 2.5の開発とDSPy 3.0の計画を進める中で、今後数週間から数ヶ月にわたるDSPyの公開ロードマップの初期案を示すものです。ロードマップに関する提案やオープンソースへの貢献を歓迎します。問題提起やプルリクエストを通じて、ぜひご意見をお寄せください。



## 技術的目標

DSPyの基本理念は、言語モデルを実用的に活用するためには、従来のアドホックなプロンプティングから、新たなプログラミングパラダイムへと移行する必要があるという点にあります。言語モデルがより汎用的な能力や構成的な能力を獲得することに頼るのではなく、開発者が問題を反復的に探索し、適切にスコープされたタスクに対して言語モデルを呼び出すモジュール型ソフトウェアを構築できるようにすることが重要です。この実現のために、DSPyは問題の分解方法とシステムの目的記述を、言語モデルの呼び出し方法や目的最大化のためのファインチューニング手法から分離するモジュール群と最適化アルゴリズムの開発に取り組んできました。DSPyの目標は、この理念に向けた抽象化、プログラミングパターン、および最適化アルゴリズムの開発（ならびに、これらの開発を共同で行うコミュニティと共有インフラの構築）にあります。

現時点でのDSPyのユーザー向け言語は、上記の目標を達成するために必要な最小限の適切な抽象化を備えています。具体的には、宣言型シグネチャ、実行時定義モジュール、および非常に強力に組み合わせ可能な最適化アルゴリズムがそれに当たります。しかし、私たちの目標を達成するためには、さらに改善すべき点がいくつか存在します。今後のDSPyリリースでは以下の目標に取り組んでいきます。

1. コア機能の完成度向上
2. より高精度で低コストな最適化アルゴリズムの開発
3. DSPyのMLワークフローからデプロイメントまでをカバーするエンドツーエンドのチュートリアルの構築
4. よりインタラクティブな最適化と追跡機能への移行



## チーム構成と組織体制

DSPyはその技術的目標、貢献者層、および対象ユーザーにおいて極めて特異な存在である。DSPyはDNNの構築と最適化のためのライブラリであるPyTorchから着想を得ているものの、重要な相違点が1つある。PyTorchはDNNが成熟した機械学習概念として確立された後に開発されたのに対し、DSPyはコア言語モデルプログラム研究の確立と発展を目的としている。このフレームワークは、プログラミング抽象概念（オリジナルの**実証-探索-予測**概念、DSPyの**シグネチャ**、**言語モデルアサーション**など）から自然言語処理システム（**STORM**、**PATH**、**IReRa**など）、プロンプト最適化器（**MIPRO**など）、強化学習（**BetterTogether**など）に至るまで、多岐にわたる関連分野の学術研究によって推進されている。

これらの研究成果はすべて、数十名に及ぶ業界関係者の貢献により、実用的で具体的なライブラリとして結実している。多くの貢献者がDSPyを本番環境でアプリケーションに採用している事実が、この成果をさらに裏付けている。このため、DSPyの対象ユーザー層は大学院生や機械学習エンジニアに留まらず、非機械学習エンジニアにまで及んでおり、早期導入型のソフトウェアエンジニアからLMの新たな活用方法を模索する趣味ユーザーまで多岐にわたる。以下のチームがOSSコミュニティの多くの協力者と共に、このロードマップに掲げる目標の実現に向けて取り組んでいる。

**プロジェクトリーダー:** オマール・カタブ（スタンフォード大学＆Databricks）

**プロジェクトメンター:** クリス・ポッツ（スタンフォード大学）、マテイ・ザハリア（カリフォルニア大学バークレー校＆Databricks）、ヘザー・ミラー（カーネギーメロン大学＆Two Sigma）

**コアライブラリ開発:** アルナヴ・シンヴィ（Databricks＆スタンフォード大学）、ヘルンブ・シャンディリヤ（スタンフォード大学）、ハンナ・モアザム（Databricks）、スリ・ヴァルダマナ（Dashworks）、サイラス・ヌルージ（Zenbase）、アミール・メフル（Zenbase）、カイル・キャヴァリー（Modular） - 特別感謝: ケシャブ・サンタナム（スタンフォード大学）、トーマス・アーレ（Normal Computing）、コナー・ショーテン（Weaviate）

**プロンプト最適化:** クリスティーナ・オプサル＝オング（スタンフォード大学）、マイケル・ライアン（スタンフォード大学）、ジョシュ・パーテル（Basis） - 特別感謝: エリック・ジャン（スタンフォード大学）

**ファインチューニング＆強化学習:** ディララ・ソイル（スタンフォード大学）、アイザック・ミラー（Anyscale）、カレル・ドスターリンク（ゲント大学） - 特別感謝: パリディ・マセシュワリ（スタンフォード大学）

**プログラミング抽象概念:** タン・シャンイン（カリフォルニア大学バークレー校）、マニシュ・シェティ（カリフォルニア大学バークレー校）、ピーター・ジョン（カーネギーメロン大学）

**応用事例:** ジャスパー・シアン（ウォータールー大学）、サロン・サミュエル（スタンフォード大学）、アルベルト・マンカレラ（スタンフォード大学）、ファラズ・コウブシラト（ウォータールー大学）、サイフル・ハク（IIT-B）、アシュトシュ・シャルマ（イリノイ大学アーバナ・シャンペーン校）



## 1) コア機能の完成度向上

今後1ヶ月間の主要な目標は機能の完成度向上であり、これは平均的なユーザー体験において最も高い投資対効果が見込まれる領域である。概念的には、DSPyのコア機能は極めて最小限に絞られている。その構成要素は（1）言語モデル、（2）シグネチャ＆モジュール、（3）オプティマイザ、（4）アサーションの4つのみである。これらの概念とその実装は、過去数年間にわたって有機的に進化してきた。現在我々は、これまでに蓄積した知見を体系化し、内部構造を再設計することで、新規ユーザーが特別なノウハウを持たずとも「すぐに使える」状態を実現するべく取り組んでいる。

より具体的には以下の通りである：

1. 我々の目標は、カスタムデータでコンパイルされていない既存のDSPyプログラム（いわゆるゼロショット・オフザシェルフ型プログラム）の品質向上を図ることである。
2. 可能な限り、DSPyは低レベルの内部処理複雑性（言語モデルの管理や構造化生成処理など）を、新たに登場している低レベルライブラリに委譲すべきである。必要に応じて、DSPyから小規模なライブラリをフォークし、それらを独立したプロジェクトとしてインフラストラクチャコンポーネントをサポートすることも検討する。
3. DSPyの内部アーキテクチャはよりモジュール化され、各コンポーネント間の互換性を高める必要がある。具体的には、以下の機能に対してより深いレベルでのネイティブな実装が求められる：
   - i) 型付きマルチフィールド制約
   - ii) アサーション機能
   - iii) 観測可能性と実験追跡機能
   - iv) アーティファクトのデプロイメントおよびストリーミング/非同期処理などの関連課題
   v) オープンモデルのファインチューニングとサービス運用機能


### 言語モデル（LM）に関する事項

DSPy 2.4時点で、本ライブラリのコード行数は約20,000行であり、テストコード、サンプルコード、ドキュメント関連コードが約10,000行存在する。これらの中にはDSPyオプティマイザのように明らかに必要不可欠なものもあるが、一方で内部処理に必要な構成要素がLM分野に存在しないために存在しているコードもある。幸いなことに、LMインターフェースに関しては既に強力なライブラリが存在する：LiteLLMである。これは各種言語モデルおよび埋め込みプロバイダー向けインターフェースを統合したライブラリである。今後は、カスタムLMや検索モデル向けのサポート機能の約6,000行のコードを、LiteLLMに移行することで削減していく予定である。

本領域における主な開発目標は以下の通りである：
- キャッシュ機能の改善
- 言語モデルの保存/読み込み機能の実装
- ストリーミングおよび非同期処理に対応したLMリクエスト機能の追加
現在この分野の開発は、Hanna MoazamとSri Vardhamananが主導しており、Cyrus Nouroozi、Amir Mehr、Kyle Caverlyらの基盤研究を発展させる形で進められている。


### シグネチャとモジュールに関する事項

従来、言語モデルはテキスト入力からテキスト出力を生成するインターフェースを提供してきた。モジュール化プログラミングの観点から、DSPyは2023年1月に初めてシグネチャ機能を導入した（DSPテンプレートとして実装）。これはLMインタラクションにおける入力と出力の構造化手法として考案されたものである。標準的なプロンプトでは、インターフェース仕様（「LMにどのような処理を行わせるべきか」）と実装方法（「その処理をどのように指示するか」）が混同されている。DSPyのシグネチャ機能ではこれらを分離することで、後者の部分をデータから推論・学習できるようにしている。これはより大きなプログラムの文脈において実現されるものである。現在のLM分野では、制約付きデコーディングなどの技術革新により、「構造化出力」の概念が劇的に進化し、主流となっている。一方、「構造化入力」と呼ばれる概念については、DSPy以外ではまだ主流とは言えないものの、同様に重要な機能である。

本領域における主な研究目的は以下の通りである：DSPyにおけるLM Adapterの抽象化と実装を第一級の概念として洗練させること。Adapterは署名とLMインターフェース間の翻訳者として機能する。Optimizerがユーザー提供の評価指標とデータに基づいてプロンプトを調整するのに対し、Adapterはより広範なLMとのインタラクション構築に注力する。具体的には、（i）チャットAPIのような非プレーンテキスト形式のLMインターフェース、構造化出力、関数呼び出し、マルチモーダルAPIなど、（ii）英語以外の言語やより高度な専門領域への対応などが挙げられる。これまでDSPyでは様々な形でこの課題に取り組んできたが、現在ではほとんどのユースケースにおいて実用的な改善をもたらす、より根本的なアプローチの開発に着手している。現在の研究活動はOmar Khattabが主導している。


### ファインチューニングとサービス提供に関する研究

2023年2月、DSPyはLMプログラムの重みを最適化するためのコンパイル概念を導入した。（AI技術の進展速度を考慮すると、これはスタンフォード大学のAlpacaトレーニングプロジェクトが開始される前、かつGPT-4の最初のリリースの1ヶ月前という極めて早い時期の成果である）その後、2023年10月および2024年7月には、DSPyのファインチューニング手法が小規模LMにおいて顕著な性能向上をもたらすことを実証した。特にプロンプト最適化と組み合わせた場合にその効果が顕著であった。

しかし実際には、DSPyのユーザーの多くは重み最適化よりもプロンプト最適化を優先的に採用しており、我々の提供する事例も同様の傾向を示している。この主な要因はインフラストラクチャにある。DSPy方式のファインチューニングは単なるモデル訓練以上の作業を必要とする：最終的には、プログラム内の複数の異なるモジュールに対する訓練データを準備し、複数のモデルを訓練して最適なモデルを選択し、それらをプログラムのモジュールに組み込む必要がある。このレベルの抽象化においてDSPyが提供する堅牢な実装を実現するには、既存の外部ツールでは一般的にサポートされていない高度なリソース管理機能が求められる。この分野における主要な取り組みは、Dilara SoyluとIsaac Millerが主導している。


### OptimizerとAssertionに関する研究

これは本研究の主要な方向性の一つであり、上記3つの研究方向についてさらに進展があった段階で、より多くの知見を共有していく予定である。


## 2) より高精度で低コストなOptimizerの開発

DSPyにおける研究の大部分は、LMプログラムのプロンプト最適化と重み最適化の最適化に焦点を当てている。2022年12月には、BootstrapFewShotアルゴリズムとその背後にある抽象化概念（DSPにおけるDemonstrateとして実装）、およびいくつかの派生手法を発表した。2023年2月には、後にBootstrapFinetuneとして発展する中核的なバージョンを導入した。2023年8月には、これら両方の手法に新たなバリエーションを追加した。2023年12月には、DSPyに初めての指示最適化手法であるCA-OPROとMIPROの初期バージョンを導入した。これらは2024年3月にさらに改良された。2024年6月から7月にかけて、プロンプト最適化向けのMIPROv2とLMプログラムの重み最適化向けのBetterTogetherをリリースした。

我々はこれまで、より高度な最適化アルゴリズムの開発に取り組んできた。現時点では新規最適化アルゴリズムに関する研究の詳細を公表することはできないものの、その開発目標について概説する。DSPy最適化アルゴリズムは以下の3つの観点で特徴づけられる：

1. 品質：各種言語モデル（LM）からどの程度の品質向上を実現できるか。また、ゼロショットプログラムが適切に機能するためには、どの程度の有効性が求められるか？
2. コスト：必要なラベル付き／ラベルなし入力データの量、プログラムの呼び出し回数、推論時における最適化済みプログラムの計算コストはどの程度か？
3. 頑健性：未知のデータポイントや分布に対してどの程度一般化可能か？また、評価指標やラベル付けにおける誤りに対してどの程度耐性があるか？

今後6ヶ月間の目標は、これら3つの観点を「他の2つの要素を一定条件下に置いた場合」に劇的に改善することである。具体的には、以下の3つの方向性で研究を進める：

- ベンチマーク構築：本研究における重要な前提条件として、ベンチマーク構築に関する取り組みがある。チームではマイケル・ライアンとシャンイン・タンがこの取り組みを主導している。詳細は追って報告する予定である。

- 品質向上：本目標は、標準的な条件下（数百件のラベル付き入力データと良好な評価指標、初期段階としての比較的良好なゼロショットプログラムを前提とする）において、DSPy最適化アルゴリズムがMIPROv2およびBetterTogetherと比較して平均20%高い性能を達成することである。この分野における各種取り組みは、ディララ・ソイル、マイケル・ライアン、ジョシュ・パーテル、クリスティーナ・オプサル＝オング、アイザック・ミラーらが主導している。

- 効率化：本目標は、MIPROv2およびBetterTogetherの現行最高スコアと同等の性能を、以下の制約条件下で達成することである：（i）ラベル付き入力データが10～20件のみの場合から、（ii）初期ゼロショットプログラムのスコアが0%という低性能状態から、（iii）訓練データ／検証データとテストデータの間に大きな乖離が存在する場合から、（iv）ユーザーが評価指標を提供せず、出力判断のサンプル数が非常に少ない場合から、それぞれ最適化を開始するケースである。



## 3) DSPyの機械学習ワークフローから展開までのエンドツーエンドチュートリアルの構築

DSPyを効果的に活用して新規タスクを解決することは、本質的には言語モデルを用いた優れた機械学習実践であるが、その教育には困難が伴う。一方で、これは反復的なプロセスである：初期段階では最適とは言えない選択を行うが、それらを段階的に改善していく。また、非常に探索的な側面も持つ：DSPy的なアプローチで問題を最適に解決する方法については、まだ誰も十分な知見を持っていない場合が多い。他方、DSPyは長年にわたる言語モデルシステム構築から得られた多くの新たな知見を提供している。この分野では、設計空間、データ特性、その他の要素が、機械学習の専門家だけでなく、機械学習経験のない大多数のユーザーにとっても新たな課題となっている。

現行のドキュメントでは[これらのトピックの一部](learn/index.md)が個別に解説されているものの、我々が得た重要な知見は、基礎となるDSPy言語自体の教育（実際これは比較的小規模な言語である）と、DSPy的な環境で効果的に機能する新たな機械学習ワークフローの教育を明確に分離すべきという点である。この自然な拡張として、DSPyにおける明示的なコーディング前後の工程――データ収集から最適化されたDSPyプログラムの実運用およびモニタリングに至るまで――により重点を置く必要がある。現在はまだ初期段階であるが、この取り組みはOmar Khattab、Isaac Miller、Herumb Shandilyaを中心に強化されていく予定である。


## 4) よりインタラクティブな最適化と追跡プロセスへの移行

現在、DSPyユーザーは最適化プロセスを観察・調整するための複数の方法を利用できる。具体的には、`inspect_history`などの最適化手法の前後でプロンプトを分析したり、組み込みのロギング機能や最適化アルゴリズムが返すメタデータを参照したりすることが可能である。同様に、`program.save`と`program.load`を使用して、最適化されたプロンプトを手動で調整することもできる。さらに、Phoenix Arize、LangWatch、Weights & Biases Weaveなどの強力な可観測性統合機能を活用することで、最適化プロセス（スコア、スタックトレース、成功/失敗事例、候補プロンプトなど）をリアルタイムで監視することも可能だ。DSPyは、最適化実行ごとにプログラム、データ、または評価指標を調整することで反復的なエンジニアリングを促進する。例えば、一部の最適化アルゴリズムでは「チェックポイント機能」が利用可能であり、BootstrapFewShotWithRandomSearchを10回実行後に15回に増やす場合、最初の10回分の結果はキャッシュから読み込まれる仕組みとなっている。

これらの機能は多くの目標を達成できるものの、今後のDSPyバージョンで解決すべき2つの重要な課題が存在する。

1. 全般的に、DSPyの（i）可観測性、（ii）実験追跡、（iii）コスト管理、および（iv）プログラムのデプロイメント機能は、MLFlowなどのツールとの連携を通じて第一級の関心事として整備されるべきである。この分野におけるDSPy 2.6向けの具体的な計画については、今後1～2ヶ月以内に詳細を共有予定である。

2. DSPy 3.0では、アドホックな人間参加型フィードバックを優先する新たな最適化アルゴリズムを導入する予定である。これは現時点で我々が近い将来にDSPyにおいて必要と考える唯一の実質的なパラダイムシフトである。この取り組みは、抽象化レベル、UI/HCI、機械学習といった様々な研究課題に関わるため、より長期的な目標であり、今後3～4ヶ月以内にさらに詳細な情報を提供する予定である。


